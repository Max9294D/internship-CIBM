# internship-CIBM
seq2seq with LSTM + attention model

you should add a folder "dataset" with your dataset in the .mat format and organize like this : 
1st column :ad,
2nd column :rd,
3rd column :md,
4th column :ak,
5th column :rk,
6th column :mk

and your outputs will be f, Da, Depar, Deperp and c2 in that order.

We used a LSTM + attention model neural network

For further information do not hesitate to contact me
